---
title: "Targets Pipeline Visualization and Diagnostics"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
    theme: cosmo
vignette: >
  %\VignetteIndexEntry{Targets Pipeline Visualization and Diagnostics}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
# Check if targets is available
has_targets <- requireNamespace("targets", quietly = TRUE)

# Find the package root directory (where _targets/ lives)
# Try multiple methods to find it
pkg_root <- tryCatch({
  # Method 1: Look for _targets relative to this file
  vignette_dir <- getwd()
  if (file.exists(file.path(vignette_dir, "_targets/meta/meta"))) {
    vignette_dir
  } else if (file.exists(file.path(dirname(vignette_dir), "_targets/meta/meta"))) {
    dirname(vignette_dir)
  } else if (file.exists(file.path(dirname(dirname(vignette_dir)), "_targets/meta/meta"))) {
    dirname(dirname(vignette_dir))
  } else {
    NULL
  }
}, error = function(e) NULL)

pipeline_exists <- has_targets && !is.null(pkg_root)

# Set evaluation based on availability
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 8,
  fig.height = 6,
  warning = FALSE,
  message = FALSE,
  echo = TRUE,  # Show code with hide/show toggle
  eval = pipeline_exists  # Only evaluate if both targets and pipeline exist
)

# Load targets only if available
if (has_targets && pipeline_exists) {
  library(targets)
}

# Exit early if prerequisites not met
if (!pipeline_exists) {
  message("Note: This vignette requires the targets package and a built targets pipeline.")
  message("Run targets::tar_make() to build the pipeline before viewing this vignette.")
  knitr::knit_exit()
}
```

## Introduction

This vignette provides comprehensive visualization and diagnostics of the `targets` pipeline used to pre-compute data for the wanikani package vignettes. All visualizations shown below are generated from pre-computed targets, demonstrating how `targets` can be used to cache expensive computations and improve vignette build times.

## Performance Metrics

**Note on Data Loading**: The visualization objects in this vignette are loaded using `readRDS()` rather than `tar_read()` because:

1. They're generated from pipeline metadata using `tar_meta()` and `tar_manifest()`
2. **The targets package explicitly prohibits calling `tar_meta()` during pipeline execution** (i.e., as a target in `_targets.R`)
3. The error message states: _"target attempted to run targets::tar_meta() during a pipeline, which is unsupported"_
4. These functions are designed to be called AFTER the pipeline completes to inspect results

Therefore, these visualization objects are generated by `generate_visualizations.R` after `tar_make()` finishes, and saved as regular RDS files rather than registered targets.

### Build Time Analysis

This section shows how long each target took to build, helping identify performance bottlenecks in the pipeline.

```{r build-times-plot, fig.height=5, fig.cap="**Figure 1**: Build time for each target in the pipeline. Longer bars indicate targets that take more time to compute."}
# Load the pre-computed plot (generated outside main pipeline to avoid recursion)
plot_build_times <- readRDS(file.path(pkg_root, "_targets/objects/plot_build_times"))
print(plot_build_times)
```

The build times table below provides detailed statistics about target execution times:

```{r build-times-table}
# Load the pre-computed table
time_stats <- readRDS(file.path(pkg_root, "_targets/objects/table_time_stats"))
knitr::kable(
  time_stats,
  caption = "**Table 1**: Summary statistics of build times across all targets",
  align = c("l", "r")
)
```

### Memory Usage Analysis

Understanding memory usage helps optimize the pipeline and identify targets that consume significant resources.

```{r memory-plot, fig.height=5, fig.cap="**Figure 2**: Memory footprint of each target. Targets with larger memory usage may benefit from data reduction or alternative storage formats."}
# Load the pre-computed memory plot
plot_memory <- readRDS(file.path(pkg_root, "_targets/objects/plot_memory_usage"))
print(plot_memory)
```

Detailed memory statistics show the distribution of resource usage across targets:

```{r memory-table}
# Load the pre-computed memory statistics table
memory_stats <- readRDS(file.path(pkg_root, "_targets/objects/table_memory_stats"))
knitr::kable(
  memory_stats,
  caption = "**Table 2**: Memory usage statistics showing total, mean, median, largest, and smallest targets",
  align = c("l", "r")
)
```

## Pipeline Structure

### Target Manifest

The target manifest shows all targets in the pipeline along with their commands, providing a complete overview of what the pipeline computes.

```{r manifest-table}
# Load the target manifest
manifest <- readRDS(file.path(pkg_root, "_targets/objects/table_manifest"))
knitr::kable(
  manifest,
  caption = "**Table 3**: Complete manifest of all targets showing their names and computation commands",
  format = "markdown"
)
```

### Dependency Graph

The dependency graph visualizes relationships between targets, showing which targets depend on others and helping identify potential parallelization opportunities.

```{r dependency-graph, eval=pipeline_exists}
# Generate interactive dependency visualization
if (requireNamespace("visNetwork", quietly = TRUE)) {
  targets::tar_visnetwork(
    targets_only = TRUE,
    label = c("time", "size")
  )
} else {
  message("Install 'visNetwork' for interactive pipeline visualization")
}
```

## Pipeline Status

### Target Progress

This section shows the current status of all targets in the pipeline, indicating which are up-to-date and which need rebuilding.

```{r progress-status}
progress <- tar_progress()

if (nrow(progress) > 0) {
  status_summary <- table(progress$progress)
  status_df <- data.frame(
    Status = names(status_summary),
    Count = as.integer(status_summary)
  )

  knitr::kable(
    status_df,
    caption = "**Table 4**: Current status of targets showing how many are built, outdated, or errored",
    col.names = c("Status", "Number of Targets")
  )
}
```

### Outdated Targets

Checking for outdated targets helps maintain pipeline freshness:

```{r outdated-check}
outdated <- tar_outdated()

if (length(outdated) > 0) {
  cat("⚠ **Outdated targets** (need rebuilding):\n\n")
  for (target in outdated) {
    cat(sprintf("- `%s`\n", target))
  }
} else {
  cat("✓ **All targets are up to date!**\n")
}
```

## System Information

### Pipeline Metadata

Pipeline metadata provides information about the environment in which targets were built:

```{r pipeline-info}
# Load pipeline metadata
metadata <- tar_read(pipeline_metadata)

info_df <- data.frame(
  Property = c("Pipeline Name", "Created At", "R Version", "Platform", "Targets Version"),
  Value = c(
    metadata$pipeline_name,
    as.character(metadata$created_at),
    metadata$r_version,
    metadata$platform,
    as.character(metadata$targets_version)
  ),
  stringsAsFactors = FALSE
)

knitr::kable(
  info_df,
  caption = "**Table 5**: Pipeline environment details showing R and targets versions used",
  row.names = FALSE
)
```

### R Session Info

Current R session information for reproducibility:

```{r session-info}
sess_info <- sessionInfo()

cat("**R Version:**", sess_info$R.version$version.string, "\n\n")
cat("**Platform:**", sess_info$platform, "\n\n")
cat("**Running under:**", sess_info$running, "\n\n")
```

## Summary and Recommendations

### Overall Statistics

```{r overall-stats}
meta <- tar_meta(fields = c("name", "time", "bytes", "seconds"))
meta_df <- as.data.frame(meta)
meta_df$seconds <- as.numeric(meta_df$seconds)
meta_df$mb <- meta_df$bytes / (1024^2)

summary_df <- data.frame(
  Metric = c(
    "Total Targets",
    "Total Build Time",
    "Total Memory Used",
    "Average Build Time",
    "Average Memory"
  ),
  Value = c(
    nrow(meta_df),
    sprintf("%.2f seconds", sum(meta_df$seconds, na.rm = TRUE)),
    sprintf("%.2f MB", sum(meta_df$mb, na.rm = TRUE)),
    sprintf("%.2f seconds", mean(meta_df$seconds, na.rm = TRUE)),
    sprintf("%.2f MB", mean(meta_df$mb, na.rm = TRUE))
  ),
  stringsAsFactors = FALSE
)

knitr::kable(
  summary_df,
  caption = "**Table 6**: Overall pipeline performance metrics",
  align = c("l", "r")
)
```

### Key Benefits of Using Targets

This pipeline demonstrates several advantages of using `targets`:

- **Caching**: Targets are only rebuilt when their dependencies change, saving computation time
- **Reproducibility**: The pipeline tracks all dependencies and can be reproduced exactly
- **Parallelization**: Independent targets can be computed in parallel
- **Monitoring**: Easy to track which targets are outdated and need updating
- **Documentation**: The pipeline itself serves as documentation of the analysis workflow

For more information on using `targets`, see the [targets documentation](https://docs.ropensci.org/targets/).
